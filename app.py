import streamlit as st
import pandas as pd
import io
from datetime import datetime

st.title("PPAãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼ç”Ÿæˆã‚¢ãƒ—ãƒªï¼ˆCSV / Excel å¯¾å¿œï¼‰")

uploaded_files = st.file_uploader(
    "CSV ã¾ãŸã¯ Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°å¯ï¼‰",
    type=["xlsx", "csv"],
    accept_multiple_files=True
)

if uploaded_files:
    dfs = []

    for file in uploaded_files:
        file_name = file.name.lower()

        try:
            if file_name.endswith(".xlsx"):
                df = pd.read_excel(file)
            elif file_name.endswith(".csv"):
                df = pd.read_csv(file, encoding="utf-8")
            else:
                st.warning(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„å½¢å¼: {file_name}")
                continue
        except Exception as e:
            st.error(f"{file_name} ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            continue

        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—åˆ—ã®ä½œæˆï¼ˆä¾‹å¤–ã«å‚™ãˆãŸå‡¦ç†ï¼‰
        try:
            df["datetime"] = pd.to_datetime(
                df["date"].astype(str) + " " + df["time"].astype(str),
                errors="coerce"
            )
            dfs.append(df.dropna(subset=["datetime"]))
        except Exception as e:
            st.error(f"{file_name} ã® datetime ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    if not dfs:
        st.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        # ãƒãƒ¼ã‚¸å‡¦ç†
        merged_df = dfs[0][["datetime"] + list(dfs[0].columns)]
        for df in dfs[1:]:
            merged_df = pd.merge(
                merged_df,
                df[["datetime", "è²·é›»é›»åŠ›é‡(kWh)", "å£²é›»é›»åŠ›é‡(kWh)", "ç™ºé›»é›»åŠ›é‡(kWh)", "æ¶ˆè²»é›»åŠ›é‡(kWh)"]],
                on="datetime",
                how="outer",
                suffixes=("", "_dup"),
            )

        # å¹³å‡å€¤ç®—å‡º
        value_cols = ["è²·é›»é›»åŠ›é‡(kWh)", "å£²é›»é›»åŠ›é‡(kWh)", "ç™ºé›»é›»åŠ›é‡(kWh)", "æ¶ˆè²»é›»åŠ›é‡(kWh)"]
        avg_df = merged_df.copy()
        for col in value_cols:
            avg_cols = [c for c in merged_df.columns if c.startswith(col)]
            avg_df[col] = merged_df[avg_cols].mean(axis=1)

        # 30åˆ†å€¤ã‚·ãƒ¼ãƒˆæ§‹æˆ
        base_df = dfs[0].copy()
        base_df["datetime"] = pd.to_datetime(base_df["date"].astype(str) + " " + base_df["time"].astype(str), errors="coerce")
        output_cols = base_df.columns.tolist()

        final_30min_df = pd.merge(
            base_df.drop(columns=value_cols),
            avg_df[["datetime"] + value_cols],
            on="datetime",
            how="left"
        )
        final_30min_df = final_30min_df[output_cols]  # åˆ—é †ã‚’å…ƒã«æˆ»ã™

        # ã‚µãƒãƒªãƒ¼ã‚·ãƒ¼ãƒˆæ§‹æˆ
        summary_df = pd.concat(dfs)
        summary_df["year"] = summary_df["year"].astype(int)
        summary_df["month"] = summary_df["month"].astype(int)
        summary_grouped = summary_df.groupby(["year", "month"])[value_cols].sum().reset_index()

        # Excelå‡ºåŠ›
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            final_30min_df.to_excel(writer, index=False, sheet_name="30åˆ†å€¤")
            summary_grouped.to_excel(writer, index=False, sheet_name="ã‚µãƒãƒªãƒ¼")

        st.success("é›†è¨ˆå®Œäº†ï¼ä»¥ä¸‹ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.download_button(
            label="ğŸ“¥ PPAãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼.xlsx ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=output.getvalue(),
            file_name="PPAãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
