import streamlit as st
import pandas as pd
import io

st.title("PPAãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼ç”Ÿæˆã‚¢ãƒ—ãƒªï¼ˆCSV / Excel å¯¾å¿œï¼‰")

uploaded_files = st.file_uploader(
    "CSV ã¾ãŸã¯ Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°å¯ï¼‰",
    type=["xlsx", "csv"],
    accept_multiple_files=True
)

def try_read_csv(file):
    encodings = ["utf-8", "cp932", "iso-8859-1"]
    for enc in encodings:
        try:
            file.seek(0)
            return pd.read_csv(file, encoding=enc)
        except Exception:
            continue
    raise ValueError("èª­ã¿è¾¼ã¿å¯èƒ½ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ã‚ã‚Šã¾ã›ã‚“")

required_cols = ["year", "month", "date", "time", "è²·é›»é›»åŠ›é‡(kWh)", "å£²é›»é›»åŠ›é‡(kWh)", "ç™ºé›»é›»åŠ›é‡(kWh)", "æ¶ˆè²»é›»åŠ›é‡(kWh)"]

if uploaded_files:
    dfs = []
    for file in uploaded_files:
        filename = file.name.lower()
        try:
            if filename.endswith(".xlsx"):
                df = pd.read_excel(file)
            elif filename.endswith(".csv"):
                df = try_read_csv(file)
            else:
                st.warning(f"æœªå¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {filename}")
                continue
        except Exception as e:
            st.error(f"{filename} ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            continue

        missing = [col for col in required_cols if col not in df.columns]
        if missing:
            st.warning(f"{filename} ã«å¿…è¦ãªåˆ—ãŒã‚ã‚Šã¾ã›ã‚“: {missing}")
            continue

        # datetimeåˆ—ã‚’ä½œã‚‹
        df["datetime"] = pd.to_datetime(df["date"].astype(str) + " " + df["time"].astype(str), errors="coerce")
        df = df.dropna(subset=["datetime"])

        dfs.append(df)

    if not dfs:
        st.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        value_cols = ["è²·é›»é›»åŠ›é‡(kWh)", "å£²é›»é›»åŠ›é‡(kWh)", "ç™ºé›»é›»åŠ›é‡(kWh)", "æ¶ˆè²»é›»åŠ›é‡(kWh)"]

        # datetimeã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ã—ã¦ concat ã—ã€åˆ—åã‚’ãƒ•ã‚¡ã‚¤ãƒ«åãªã©ã§ä¸€æ„ã«ã—ãªãŒã‚‰å¹³å‡ã‚’è¨ˆç®—
        df_list_for_avg = []
        for i, df in enumerate(dfs):
            tmp = df.set_index("datetime")[value_cols].copy()
            # åˆ—åã‚’ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–
            tmp.columns = [f"{col}_file{i}" for col in value_cols]
            df_list_for_avg.append(tmp)

        combined = pd.concat(df_list_for_avg, axis=1)
        avg_df = pd.DataFrame(index=combined.index)
        for col in value_cols:
            cols = [c for c in combined.columns if c.startswith(col)]
            avg_df[col] = combined[cols].mean(axis=1)

        avg_df = avg_df.reset_index()

        # 30åˆ†å€¤ã‚·ãƒ¼ãƒˆã®å…ƒãƒ‡ãƒ¼ã‚¿ã¯æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ™ãƒ¼ã‚¹ã«å¹³å‡å€¤ã‚’çµåˆ
        base_df = dfs[0].copy()
        base_df = base_df.drop(columns=value_cols)
        final_30min_df = pd.merge(base_df, avg_df, on="datetime", how="left")

        # ã‚µãƒãƒªãƒ¼ã‚·ãƒ¼ãƒˆï¼šã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å€¤ã‚’ç¸¦ã«é€£çµã—ã¦å¹´ãƒ»æœˆæ¯ã®åˆè¨ˆã‚’ç®—å‡º
        summary_df = pd.concat(dfs, ignore_index=True)
        summary_df["year"] = summary_df["year"].astype(int)
        summary_df["month"] = summary_df["month"].astype(int)
        summary_grouped = summary_df.groupby(["year", "month"])[value_cols].sum().reset_index()

        # Excelå‡ºåŠ›
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            final_30min_df.to_excel(writer, index=False, sheet_name="30åˆ†å€¤")
            summary_grouped.to_excel(writer, index=False, sheet_name="ã‚µãƒãƒªãƒ¼")

        st.success("âœ… é›†è¨ˆå®Œäº†ï¼ä¸‹è¨˜ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.download_button(
            label="ğŸ“¥ PPAãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼.xlsx ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=output.getvalue(),
            file_name="PPAãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
